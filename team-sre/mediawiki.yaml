# deploy-tag: ops
# deploy-site: eqiad, codfw

groups:
  - name: appservers
    rules:
      - &PHPFPMTooBusy
        alert: PHPFPMTooBusy
        annotations:
          description: 'The MediaWiki cluster {{ $labels.cluster }} in {{ $externalLabels.site }} is experiencing saturation of {{ $labels.service }} workers {{ $value | humanizePercentage }}'
          summary: 'Not enough idle {{ $labels.service }} workers for Mediawiki {{ $labels.cluster }} at {{ $externalLabels.site }} #page'
          dashboard: 'https://grafana.wikimedia.org/d/RIA1lzDZk/application-servers-red-dashboard?from=now-3h&orgId=1&to=now&var-cluster={{ $labels.cluster }}&var-site={{ $externalLabels.site }}&viewPanel=64'
          runbook: 'https://bit.ly/wmf-fpmsat'
        expr:
          sum by (cluster, service) (phpfpm_statustext_processes{cluster=~"(api_appserver|appserver)", state="idle"})
          /
          sum by (cluster, service) (phpfpm_statustext_processes{cluster=~"(api_appserver|appserver)"})
          <= 0.3
        for: 2m
        labels:
          severity: page
          team: sre

      - <<: *PHPFPMTooBusy
        expr: sum by (cluster, service) (phpfpm_statustext_processes{cluster=~"(parsoid)", state="idle"})
          /
          sum by (cluster, service) (phpfpm_statustext_processes{cluster=~"(parsoid)"})
          <= 0.15
        for: 5m

      - alert: JobrunnerPHPBusyWorkers
        annotations:
          description: 'Jobrunners in {{ $externalLabels.site }} is experiencing saturation of php-fpm workers: {{ $value | humanizePercentage }} for more than 10 minutes.'
          summary: 'Not enough idle {{ $labels.service }} workers for Mediawiki {{ $labels.cluster }} at {{ $externalLabels.site }}'
          dashboard: 'https://grafana.wikimedia.org/d/wqj6s-unk/jobrunners?fullscreen&orgId=1&from=now-3h&to=now&var-datasource={{ $externalLabels.site }}%20prometheus/ops&viewPanel=54'
          runbook: 'https://bit.ly/wmf-fpmsat'
        expr: sum by (cluster, service) (phpfpm_statustext_processes{cluster="jobrunner", state="idle"})
          /
          sum by (cluster, service) (phpfpm_statustext_processes{cluster="jobrunner"})
          <= 0.1
        for: 10m
        labels:
          severity: critical
          team: sre

      - &AppserversUnreachable
        alert: AppserversUnreachable
        annotations:
          description: 'Prometheus in {{ $externalLabels.site }} is unable to scrape metrics for {{ $value | humanizePercentage }} of cluster {{ $labels.cluster }}.'
          summary: 'Appserver unavailable for cluster {{ $labels.cluster }} at {{ $externalLabels.site }}'
          dashboard: 'https://grafana.wikimedia.org/d/RIA1lzDZk/application-servers-red-dashboard?orgId=1&var-site={{ $externalLabels.site }}&var-cluster={{ $labels.cluster }}'
          runbook: 'https://wikitech.wikimedia.org/wiki/Application_servers'
        expr: sum(up{job="apache",cluster=~"(api_appserver|appserver|jobrunner|parsoid)"}) by (cluster)
          /
          count(up{job="apache",cluster=~"(api_appserver|appserver|jobrunner|parsoid)"}) by (cluster)
          <= 0.9
        for: 4m
        labels:
          severity: critical
          team: sre

      # Re-use the alert above and check that apache-exporter can actually talk
      # to apache itself (i.e. apache_up == 1)
      - <<: *AppserversUnreachable
        expr: sum(apache_up{job="apache",cluster=~"(api_appserver|appserver|jobrunner|parsoid)"}) by (cluster)
          /
          count(apache_up{job="apache",cluster=~"(api_appserver|appserver|jobrunner|parsoid)"}) by (cluster)
          <= 0.9

      # Latency alerts:
      # we alert on the average request time
      # Case 1: appserver GET: 0.4s threshold and 100 rps
      - &MediaWikiLatencyExceeded
        alert: MediaWikiLatencyExceeded
        annotations:
          description: 'The mediawiki cluster {{ $labels.cluster }} in {{ $externalLabels.site }} is experiencing slowness. The average latency for {{ $labels.method }}/{{ $labels.code }}: {{ $value }}s'
          summary: 'Average latency high: {{ $externalLabels.site }} {{ $labels.cluster }} {{ $labels.method }}/{{ $labels.code }}: {{ $value }}s'
          dashboard: 'https://grafana.wikimedia.org/d/RIA1lzDZk/application-servers-red-dashboard?panelId=9&fullscreen&orgId=1&from=now-3h&to=now&var-site={{ $externalLabels.site }}&var-cluster={{ $labels.cluster }}&var-method={{ $labels.method }}'
          runbook: 'https://wikitech.wikimedia.org/wiki/Application_servers/Runbook#Average_latency_exceeded'
        expr: >
          sum(
            cluster_code_method_handler:mediawiki_http_requests_duration:avg2m{cluster="appserver",method="GET", handler=~"proxy:unix:.*"}
          ) by (code,cluster,handler,method) > 0.4
          and sum(
            rate(mediawiki_http_requests_duration_count{cluster="appserver",method="GET", handler=~"proxy:unix:.*"}[2m])
          ) by (code,cluster,handler,method) > 100
        for: 4m
        labels:
          severity: critical
          team: sre

      # Case 2: api GET: 0.2s threshold and 100 rps
      - <<: *MediaWikiLatencyExceeded
        expr: >
          sum(
            cluster_code_method_handler:mediawiki_http_requests_duration:avg2m{cluster="api_appserver",method="GET", handler=~"proxy:unix:.*"}
          ) by (code,cluster,handler,method) > 0.2
          and sum(
            rate(mediawiki_http_requests_duration_count{cluster="api_appserver",method="GET", handler=~"proxy:unix:.*"}[2m])
          ) by (code,cluster,handler,method) > 100

      # Case 3: parsoid GET: 2s threshold and 20 rps, for 10m
      - <<: *MediaWikiLatencyExceeded
        expr: >
          sum(
            cluster_code_method_handler:mediawiki_http_requests_duration:avg2m{cluster="parsoid",method="GET", handler=~"proxy:unix:.*"}
          ) by (code,cluster,handler,method) > 2.0
          and sum(
            rate(mediawiki_http_requests_duration_count{cluster="parsoid",method="GET", handler=~"proxy:unix:.*"}[2m])
          ) by (code,cluster,handler,method) > 20
        for: 10m

      # Case 3b: parsoid GET: 4s threshold and 20 rps, for 5m
      - <<: *MediaWikiLatencyExceeded
        expr: >
          sum(
            cluster_code_method_handler:mediawiki_http_requests_duration:avg2m{cluster="parsoid",method="GET", handler=~"proxy:unix:.*"}
          ) by (code,cluster,handler,method) > 4.0
          and sum(
            rate(mediawiki_http_requests_duration_count{cluster="parsoid",method="GET", handler=~"proxy:unix:.*"}[2m])
          ) by (code,cluster,handler,method) > 20
        for: 5m

      # Case 4: appserver POST: 2s threshold of 5 rps
      - <<: *MediaWikiLatencyExceeded
        expr: >
          sum(
            cluster_code_method_handler:mediawiki_http_requests_duration:avg2m{cluster="appserver",method="POST", handler=~"proxy:unix:.*"}
          ) by (code,cluster,handler,method) > 2.0
          and sum(
            rate(mediawiki_http_requests_duration_count{cluster="appserver",method="POST", handler=~"proxy:unix:.*"}[2m])
          ) by (code,cluster,handler,method) > 5

      # Case 5: api POST: 0.4s, 20 rps
      - <<: *MediaWikiLatencyExceeded
        expr: >
          sum(
            cluster_code_method_handler:mediawiki_http_requests_duration:avg2m{cluster="api_appserver",method="POST", handler=~"proxy:unix:.*"}
          ) by (code,cluster,handler,method) > 0.4
          and sum(
            rate(mediawiki_http_requests_duration_count{cluster="api_appserver",method="POST", handler=~"proxy:unix:.*"}[2m])
          ) by (code,cluster,handler,method) > 20
      # We don't have parsoid POST alerts because those should not happen.
      # Mediawiki error channels related alerts
      # TODO: set to paging?
      - alert: MediaWikiMemcachedHighErrorRate
        annotations:
          description: 'Elevated global rate of errors connecting to memcached from MediaWiki: {{ $value }} errors/min'
          summary: 'MediaWiki memcached error rate is elevated globally'
          dashboard: 'https://grafana.wikimedia.org/d/000000438/mediawiki-exceptions-alerts?var-datasource={{ $externalLabels.site }}%20prometheus/ops&viewPanel=19'
          runbook: 'https://wikitech.wikimedia.org/wiki/Application_servers/Runbook'
        labels:
          severity: critical
          team: sre
        for: 2m
        expr: sum(log_mediawiki_servergroup_level_channel_doc_count{channel="memcached", level="ERROR"}) > 5000

      # Mediawiki fatals and exceptions per MediaWiki cluster.
      - alert: MediaWikiHighErrorRate
        annotations:
          description: 'Elevated global rate of errors and fatals from MediaWiki in server group {{ $labels.servergroup }}: {{$value}}/min'
          summary: 'Elevated rate of MediaWiki errors - {{ $labels.servergroup }}'
          dashboard: 'https://grafana.wikimedia.org/d/000000438/mediawiki-exceptions-alerts?panelId=18&fullscreen&orgId=1&var-datasource={{ $externalLabels.site }}%20prometheus/ops'
          runbook: 'https://wikitech.wikimedia.org/wiki/Application_servers/Runbook'
        labels:
          severity: critical
          team: sre
        for: 2m
        expr: 'sum(log_mediawiki_servergroup_level_channel_doc_count{channel=~"(fatal|exception)", level="ERROR"}) by (servergroup) > 100'
