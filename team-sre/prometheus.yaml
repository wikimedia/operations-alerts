# deploy-tag: ops

# Job and exporter related alerts
groups:
  - name: prometheus
    rules:
    - &job_unavailable
      alert: JobUnavailable
      annotations:
        description: The Prometheus job {{ $labels.job }} running on {{ $externalLabels.prometheus }}@{{ $externalLabels.site }}
          reports {{ $value | humanizePercentage }} of its targets were scrape-able.
          Check if the targets are reachable and exporting metrics.
        summary: Reduced availability for job {{ $labels.job }} in {{ $externalLabels.prometheus }}@{{ $externalLabels.site }}
        dashboard: 'https://grafana.wikimedia.org/d/NEJu05xZz/prometheus-targets'
        runbook: 'https://wikitech.wikimedia.org/wiki/Prometheus#Prometheus_job_unavailable'
      # See https://phabricator.wikimedia.org/T276749 for netbox_device_statistics
      # 'rails' excluded until Alertmanager migration https://phabricator.wikimedia.org/T289454
      expr: 0.6 >= sum by (job) (up{job!~"(netbox_device_statistics|rails)"}) / count by (job) (up)
      for: 5m
      labels:
        severity: warning
        team: sre

    - <<: *job_unavailable
      expr: 0.5 >= sum by (job) (up{job!~"(netbox_device_statistics|rails)"}) / count by (job) (up)
      labels:
        severity: critical
        team: sre

    - &lint_problem
      alert: AlertLintProblem
      annotations:
        description: 'Pint reporter {{ $labels.reporter }} found problem(s) in {{ $labels.filename }}: {{ $labels.problem }}'
        summary: Linting problems found for {{ $labels.name }}
        dashboard: TODO
        runbook: https://wikitech.wikimedia.org/wiki/Alertmanager#Alert_linting_found_problems
          #expr: count without (severity) (pint_problem) > 0
      expr: pint_problem > 0
      for: 30m
      labels:
        severity: warning
        team: sre

    # Open tasks for alerts with lingering lint problems
    - <<: *lint_problem
      for: 14d
      labels:
        severity: task
        team: sre
