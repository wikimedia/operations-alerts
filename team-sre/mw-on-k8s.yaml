# deploy-tag: k8s
groups:
  - name: mediawiki-on-k8s
    rules:
      # PHPFPMTooBusy is a capacity-sensitive alert, so its aggregation should
      # reflect common pools of capacity, which may span releases.
      # In these cases, we aggregate by routed_via, and use the "primary"
      # associated release as the release hint in the dashboard link.
      - &PHPFPMTooBusy
        alert: PHPFPMTooBusy
        annotations:
          description: 'The MediaWiki k8s deployment {{ $labels.deployment }} in {{ $externalLabels.site }} is experiencing saturation of PHP-FPM workers in releases routed via {{ $labels.routed_via }}: {{ $value | humanizePercentage }} idle'
          summary: 'Not enough idle PHP-FPM workers for Mediawiki {{ $labels.deployment }} releases routed via {{ $labels.routed_via }} at {{ $externalLabels.site }}: {{ $value | humanizePercentage }} idle'
          dashboard: 'https://grafana.wikimedia.org/d/U7JT--knk/mw-on-k8s?orgId=1&viewPanel=84&var-dc={{ $externalLabels.site }}%20prometheus/k8s&var-service=mediawiki&var-namespace={{$labels.deployment}}&var-container_name=All&var-release={{ $labels.routed_via }}'
          runbook: 'https://bit.ly/wmf-fpmsat'
        expr: sum by (deployment, routed_via) (phpfpm_processes_total{app="mediawiki", state="idle", deployment!~"mw-jobrunner|mw-debug|mw-parsoid|mw-experimental"}) / sum by (deployment, routed_via) (phpfpm_processes_total{app="mediawiki", deployment!~"mw-jobrunner|mw-debug|mw-parsoid|mw-experimental"}) <= 0.25
        for: 2m
        labels:
          severity: critical
          team: sre
      - <<: *PHPFPMTooBusy
        expr: sum by (deployment, routed_via) (phpfpm_processes_total{app="mediawiki", state="idle", deployment="mw-jobrunner"}) / sum by (deployment, routed_via) (phpfpm_processes_total{app="mediawiki", deployment="mw-jobrunner"}) <= 0.1

      - alert: HttpdUnreachable
        annotations:
          description: 'httpd is unresponsive on {{ $value | humanizePercentage }} of MediaWiki k8s deployment {{ $labels.deployment }}/{{ $labels.release }}.'
          summary: 'httpd unavailable for deployment {{ $labels.deployment }}/{{ $labels.release }} at {{ $externalLabels.site }}'
          dashboard: 'https://grafana.wikimedia.org/d/U7JT--knk/mw-on-k8s?orgId=1&viewPanel=257&var-dc={{ $externalLabels.site }}%20prometheus/k8s&var-service=mediawiki&var-namespace={{ $labels.deployment }}&var-release={{ $labels.release }}'
          runbook: 'https://wikitech.wikimedia.org/wiki/Application_servers'
        expr: sum(apache_up{app="mediawiki"}) by (deployment, release)
          /
          count(apache_up{app="mediawiki"}) by (deployment, release)
          <= 0.9
        for: 4m
        labels:
          severity: critical
          team: sre

      # Latency alert:
      # * We alert on the 75th percentile of request time. We use p75 instead
      #   of p99 here to avoid the effect of a few slow requests to cause false
      #   negatives.
      # * Limits are for now 800ms and at least 300 rps (so about 60 rps slower
      #   than 800 ms).
      # * However, if p75 is above 1s, even with less than 300 rps, we also
      #   want to alert.
      # * For now, we're using envoy's metrics so we can't differentiate by
      #   HTTP method or response code.
      #
      # MediaWikiLatencyExceeded is also a capacity-sensitive alert, so we
      # again aggregate by routed_via. See discussion on PHPFPMTooBusy above.
      - &MediaWikiLatencyExceeded
        alert: MediaWikiLatencyExceeded
        annotations:
          description: 'The MediaWiki k8s deployment {{ $labels.deployment }} in {{ $externalLabels.site }} is experiencing slowness in releases routed via {{ $labels.routed_via }}. 75th percentile latency: {{ $value | humanizeDuration }}'
          summary: 'p75 latency high: {{ $externalLabels.site }} {{ $labels.deployment }} releases routed via {{ $labels.routed_via }} (k8s) {{ $value | humanizeDuration }}'
          dashboard: 'https://grafana.wikimedia.org/d/U7JT--knk/mw-on-k8s?orgId=1&viewPanel=55&var-dc={{ $externalLabels.site }}%20prometheus/k8s&var-service=mediawiki&var-namespace={{ $labels.deployment }}&var-release={{ $labels.routed_via }}'
          runbook: 'https://wikitech.wikimedia.org/wiki/Application_servers/Runbook#Average_latency_exceeded'
        expr: >
          histogram_quantile(
            0.75,
            sum(
              rate(envoy_cluster_upstream_rq_time_bucket{ app="mediawiki", envoy_cluster_name=~"(local_service|LOCAL_.*)", deployment!~"mw-jobrunner|mw-parsoid|mw-experimental"}[2m])
            ) by (le, deployment, routed_via)
          ) / 1000 > 0.8
          and sum(
            rate(envoy_cluster_upstream_rq_time_count{app="mediawiki",envoy_cluster_name=~"(local_service|LOCAL_.*)", deployment!~"mw-jobrunner|mw-parsoid|mw-experimental"}[2m])
          ) by (deployment, routed_via) > 300
        for: 4m
        labels:
          severity: critical
          team: sre
      # However, if p75 is above 1s, even with less than 300rps, we want to alert
      - <<: *MediaWikiLatencyExceeded
        expr: >
          histogram_quantile(
            0.75,
            sum(
              rate(envoy_cluster_upstream_rq_time_bucket{ app="mediawiki", envoy_cluster_name=~"(local_service|LOCAL_.*)", deployment!~"mw-jobrunner|mw-parsoid|mw-experimental"}[2m])
            ) by (le, deployment, routed_via)
          ) / 1000 > 1
