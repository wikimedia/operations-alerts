# deploy-tag: k8s
groups:
  - name: api-gateway
    rules:
      - alert: GatewayBackendErrorsHigh
        annotations:
          description: 'High number of 5xx responses from {{ $labels.envoy_cluster_name }} via {{ $labels.kubernetes_namespace }} in {{ $externalLabels.site }}'
          summary: '{{ $labels.kubernetes_namespace }}: elevated 5xx errors from {{ $labels.envoy_cluster_name }} in {{ $externalLabels.site }} #page'
          dashboard: 'https://grafana.wikimedia.org/d/UOH-5IDMz/api-and-rest-gateway?orgId=1&refresh=30s&viewPanel=57&var-datasource={{ $externalLabels.site }}%20prometheus/k8s&var-instance={{ $labels.kubernetes_namespace }}'
          runbook: 'https://wikitech.wikimedia.org/wiki/API_Gateway#How_to_debug_it'
        # Historically only real outages would've triggered this alert by keeping errors over 5 per second per backend for over 10 minutes.
        expr: sum(irate(envoy_cluster_upstream_rq{kubernetes_namespace=~"(api|rest)-gateway", envoy_response_code=~"5[0-9]+"}[5m])) by (kubernetes_namespace, envoy_cluster_name) > 5
        for: 10m
        labels:
          severity: page
          team: sre