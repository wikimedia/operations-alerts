groups:
  - name: logstash
    rules:

    - alert: LogstashNoLogsIndexed
      annotations:
        description: Logstash logs are not being indexed by Elasticsearch
        summary: Logstash logs are not being indexed by Elasticsearch
        dashboard: https://grafana.wikimedia.org/d/000000561/logstash
        runbook: https://wikitech.wikimedia.org/wiki/Logstash#No_logs_indexed
      expr: sum(irate(elasticsearch_indices_indexing_index_total{cluster="logstash"}[5m])) < 100
      for: 1m
      labels:
        severity: critical
        team: o11y

#   Alert on unusual day-over-day logstash ingestion rate change - T202307
    - alert: LogstashIngestSpike
      annotations:
        description: Logstash is ingesting {{ $value }}% more than what it did this same time yesterday.  Check for a log producer generating a high volume of logs.
        summary: Logstash rate of ingestion percent change compared to yesterday
        dashboard: https://grafana.wikimedia.org/dashboard/db/logstash?orgId=1&panelId=2&fullscreen
        runbook: https://phabricator.wikimedia.org/T202307
      expr: |
        100 * (
          sum(
            rate(logstash_node_plugin_events_out_total{plugin_id=~"input/.*"}[5m])
          ) / sum(
            rate(logstash_node_plugin_events_out_total{plugin_id=~"input/.*"}[5m] offset 1d)
          )
        ) > 210
      for: 10m
      labels:
        severity: critical
        team: o11y

# Logstash Elasticsearch indexing failures - T236343 T240667
    - alert: LogstashIndexingFailures
      annotations:
        description: Increase in logs received by the Dead Letter Queue and not indexed properly
          due to log message mapping or parsing issues.  Check the DLQ saved search in Logstash for more details.
        summary: Logstash Elasticsearch indexing errors
        dashboard: https://grafana.wikimedia.org/d/000000561/logstash?viewPanel=40
        runbook: https://wikitech.wikimedia.org/wiki/Logstash#Indexing_errors
      # Gauge of total hits that minute.  total_hits/60 = events/sec
      expr: sum(log_dead_letters_hits) / 60 > 8
      for: 1m
      labels:
        severity: critical
        team: o11y

    - alert: LogstashKafkaConsumerLag
      annotations:
        description: Logstash consumers are not keeping up with the rate of log production.
          Either Logstash has reduced throughput capacity or log generators are producing too many logs.
        summary: Too many messages in kafka logging
        dashboard: https://grafana.wikimedia.org/d/000000484/kafka-consumer-lag?var-cluster={{ $labels.exported_cluster }}
        runbook: https://wikitech.wikimedia.org/wiki/Logstash#Kafka_consumer_lag
      expr: sum by (exported_cluster) (kafka_burrow_partition_lag{exported_cluster=~"logging-.*"}) > 1500
      for: 1m
      labels:
        severity: critical
        team: o11y

    - alert: LogstashUdpLoss
      annotations:
        description: Logstash node is dropping more than 10% of its received UDP packets.
          Usually, this means Logstash needs a restart.
        summary: Packet loss ratio for UDP > 10% on {{ $labels.instance }}
        dashboard: https://grafana.wikimedia.org/d/000000561/logstash?viewPanel=1
        runbook: https://wikitech.wikimedia.org/wiki/Logstash#UDP_packet_loss
      # >10%
      expr: |
        (
          sum by (instance) (
            rate(node_netstat_Udp_InErrors{instance=~"logstash.*"}[5m])
          ) / (
            sum by (instance) (
              rate(node_netstat_Udp_InErrors{instance=~"logstash.*"}[5m])
            ) + sum by (instance) (
              rate(node_netstat_Udp_InDatagrams{instance=~"logstash.*"}[5m])
            )
          )
        ) > 0.1
      for: 1m
      labels:
        severity: critical
        team: o11y
