# deploy-tag: ops
# deploy-site: eqiad, codfw

groups:
  - name: logstash
    rules:

    - alert: LogstashNoLogsIndexed
      annotations:
        description: Logstash logs are not being indexed by Elasticsearch
        summary: Logstash logs are not being indexed by Elasticsearch
        dashboard: https://grafana.wikimedia.org/d/000000561/logstash?var-datasource={{ $externalLabels.site }}%20prometheus/ops
        runbook: https://wikitech.wikimedia.org/wiki/Logstash#No_logs_indexed
      expr: sum(irate(elasticsearch_indices_indexing_index_total{cluster="logstash"}[5m])) < 100
      for: 1m
      labels:
        severity: critical
        team: o11y

# Logstash Elasticsearch indexing failures - T236343 T240667
    - alert: LogstashIndexingFailures
      annotations:
        description: Increase in logs received by the Dead Letter Queue and not indexed properly
          due to log message mapping or parsing issues.  Check the DLQ saved search in Logstash for more details.
        summary: Logstash Elasticsearch indexing errors
        dashboard: https://grafana.wikimedia.org/d/000000561/logstash?viewPanel=40&var-datasource={{ $externalLabels.site }}%20prometheus/ops
        runbook: https://wikitech.wikimedia.org/wiki/Logstash#Indexing_errors
      # Gauge of total hits that minute.  total_hits/60 = events/sec
      expr: sum(log_dead_letters_hits) / 60 > 8
      for: 1m
      labels:
        severity: critical
        team: o11y

    - &logstash_kafka_lag
      alert: LogstashKafkaConsumerLag
      annotations:
        description: Logstash consumers are not keeping up with the rate of log production.
          Either Logstash has reduced throughput capacity or log generators are producing too many logs.
        summary: Too many messages in {{ $labels.exported_cluster }} for group {{ $labels.group }}
        dashboard: https://grafana.wikimedia.org/d/000000484/kafka-consumer-lag?var-cluster={{ $labels.exported_cluster }}&var-datasource={{ $externalLabels.site }}%20prometheus/ops
        runbook: https://wikitech.wikimedia.org/wiki/Logstash#Kafka_consumer_lag
      expr: sum by (exported_cluster, group) (kafka_burrow_partition_lag{exported_cluster=~"logging-.*"}) > 1500
      for: 10m
      labels:
        severity: critical
        team: o11y

    - <<: *logstash_kafka_lag
      expr: sum by (exported_cluster, group) (kafka_burrow_partition_lag{exported_cluster=~"logging-.*"}) > 500000
      for: 2m

    - alert: LogstashUdpLoss
      annotations:
        description: Logstash node is dropping more than 10% of its received UDP packets.
          Usually, this means Logstash needs a restart.
        summary: Packet loss ratio for UDP > 10% on {{ $labels.instance }}
        dashboard: https://grafana.wikimedia.org/d/000000561/logstash?viewPanel=1&var-datasource={{ $externalLabels.site }}%20prometheus/ops
        runbook: https://wikitech.wikimedia.org/wiki/Logstash#UDP_packet_loss
      # >10%
      expr: |
        (
          sum by (instance) (
            rate(node_netstat_Udp_InErrors{instance=~"logstash.*"}[5m])
          ) / (
            sum by (instance) (
              rate(node_netstat_Udp_InErrors{instance=~"logstash.*"}[5m])
            ) + sum by (instance) (
              rate(node_netstat_Udp_InDatagrams{instance=~"logstash.*"}[5m])
            )
          )
        ) > 0.1
      for: 1m
      labels:
        severity: critical
        team: o11y
