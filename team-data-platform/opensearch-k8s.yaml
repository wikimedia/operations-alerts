# deploy-tag: k8s-dse
# deploy-site: eqiad, codfw
groups:
  - name: opensearch_on_k8s
  # alerts generated by the official OpenSearch on K8s mixin, ref T408640 for more details
  # see also https://docs.opensearch.org/latest/install-and-configure/configuring-opensearch/cluster-settings/#cluster-level-routing-and-allocation-settings ;
  # specifically, the `cluster.routing.allocation.disk.watermark.low` and `cluster.routing.allocation.disk.watermark.high` settings
    rules:
    - "alert": "OpenSearchNodeLowDiskWatermarkReached"
      "annotations":
        dashboard: "https://w.wiki/HKe3"
        runbook: "https://w.wiki/HKer"
        "description": "Disk Low Watermark Reached at {{ $labels.node }} node in {{ $labels.cluster }} cluster. Shards can not be allocated to this node anymore. You should consider adding more disk to the node."
        "summary": "Disk Low Watermark Reached - disk saturation is {{ $value }}%"
      "expr": |
        sum by (cluster, instance, node) (
          round(
            (1 - (
              opensearch_fs_path_available_bytes /
              opensearch_fs_path_total_bytes
            )
          ) * 100, 0.001)
        ) > opensearch_cluster_routing_allocation_disk_watermark_low_pct
      "for": "5m"
      "labels":
        "severity": "warning"
        "team": "data-platform"
    - "alert": "OpenSearchNodeHighDiskWatermarkReached"
      "annotations":
        dashboard: "https://w.wiki/HKe3"
        runbook: "https://w.wiki/HKer"
        "description": "Disk High Watermark Reached at {{ $labels.node }} node in {{ $labels.cluster }} cluster. Some shards will be re-allocated to different nodes if possible. Make sure more disk space is added to the node or drop old indices allocated to this node."
        "summary": "Disk High Watermark Reached - disk saturation is {{ $value }}%"
      "expr": |
        sum by (cluster, instance, node) (
          round(
            (1 - (
              opensearch_fs_path_available_bytes /
              opensearch_fs_path_total_bytes
            )
          ) * 100, 0.001)
        ) > opensearch_cluster_routing_allocation_disk_watermark_high_pct
      "for": "5m"
      "labels":
        "severity": "critical"
        "team": "data-platform"
    - "alert": "OpenSearchClusterAtLeastOneRedIndex"
      "annotations":
        dashboard: "https://w.wiki/HLXP"
        runbook: "https://w.wiki/HKer"
        "description": "Cluster {{ $labels.cluster }} health status has been RED for at least 5m, writes will not be accepted on red indices. Check _cat/shards or _cat/indices to find the red indices."
        "summary": "Cluster health status is RED"
      "expr": |
        sum by (cluster) (opensearch_cluster_status == 5)
      "for": "5m"
      "labels":
        "severity": "critical"
        "team": "data-platform"
    - "alert": "OpenSearchBulkRequestsRejectionJumps"
      "annotations":
        dashboard: "https://w.wiki/HLXP"
        runbook: "https://w.wiki/HKer"
        description: "High Bulk Rejection Ratio at {{ $labels.node }} node in {{ $labels.cluster }} cluster. This node may not be keeping up with the indexing speed."
        summary: "High Bulk Rejection Ratio - {{ $value }}%"
      "expr": |
        round( bulk:reject_ratio:rate2m * 100, 0.001 ) > 5
      "for": "10m"
      "labels":
        "severity": "critical"
        "team": "data-platform"
    - "alert": "OpenSearchJVMHeapUseHigh"
      "annotations":
        dashboard: "https://w.wiki/HLXP"
        runbook: "https://w.wiki/HKer"
        "description": "JVM Heap usage on the node {{ $labels.node }} in {{ $labels.cluster }} cluster is {{ $value }}%."
        "summary": "JVM Heap usage on the node is high"
      "expr": |
        sum by (cluster, instance, node) (opensearch_jvm_mem_heap_used_percent) > 94
      "for": "10m"
      "labels":
        "severity": "critical"
        "team": "data-platform"
