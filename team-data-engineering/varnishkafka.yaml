groups:
  - name: varnishkafka
    rules:
      # If Varnish is receiving requests, but VarnishKafka is not sending enough messages to Kafka, fire the alert.
      # We fire a warning if the rate of kafka messages is less than 20% of the rate of varnish requests over a 5 minutes period.
      # These values have been chosen in order to avoid false alerts from stop/start events.
      # The label_replace function is used to generate hostnames from instance, so that we can match the two series from different exporters.
      - alert: VarnishkafkaNoMessages
        expr: sum by (hostname,cluster) (label_replace (rate(rdkafka_producer_topic_partition_msgs[5m]), "hostname", "$1", "instance", "(.*):.*")) / sum by (cluster,hostname) (label_replace (rate(varnish_requests{ method!~"PURGE"}[5m]), "hostname", "$1", "instance", "(.*):.*")) < 0.2
        labels:
          team: data-engineering
          severity: warning
        annotations: &varnishkafka-nomessages-annotations
          summary: 'varnishkafka on {{ $labels.hostname }} is not sending enough {{ $labels.cluster }} requests'
          description: 'Varnish on {{ $labels.hostname }} is receiving requests, but Varnishkafka is not sending enough {{ $labels.cluster }} requests'
          dashboard: 'https://grafana.wikimedia.org/d/000000253/varnishkafka?orgId=1&var-datasource={{ $externalLabels.site }}%20prometheus/ops&var-cp_cluster={{ $labels.cluster }}&var-instance={{ $labels.hostname }}%3A9132&viewPanel=14'
          runbook: 'https://wikitech.wikimedia.org/wiki/Analytics/Systems/Varnishkafka'

      # Fire a critical alert if fewer than 10% of the requests are logged to kafka over the same 5 minutes window.
      - alert: VarnishkafkaNoMessages
        expr: sum by (hostname,cluster) (label_replace (rate(rdkafka_producer_topic_partition_msgs[5m]), "hostname", "$1", "instance", "(.*):.*")) / sum by (cluster,hostname) (label_replace (rate(varnish_requests{ method!~"PURGE"}[5m]), "hostname", "$1", "instance", "(.*):.*")) < 0.1
        labels:
          team: data-engineering
          severity: critical
        annotations: *varnishkafka-nomessages-annotations

      # Let's get concerned when we average more than 1 error per second per
      # caching method, instance, and datacenter.
      - alert: VarnishKafkaDeliveryErrors
        expr: sum by (cluster, instance, site) (irate(varnishkafka_delivery_errors_total[5m])) >= 1
        labels:
          team: data-engineering
          severity: warning
        annotations: &varnishkafka-annotations
          summary: 'varnishkafka has {{ $labels.cluster }} errors on {{ $labels.instance }}'
          description: 'varnishkafka is experiencing {{ $labels.cluster }} errors on the instance {{ $labels.instance }} in the {{ $externalLabels.site }} datacenter.'
          dashboard: 'https://grafana.wikimedia.org/d/000000253/varnishkafka?panelId=20&fullscreen&orgId=1&var-datasource={{ $externalLabels.site }}%20prometheus/ops&var-cp_cluster={{ $labels.cluster }}&var-instance={{ $labels.instance | reReplaceAll "^([^:]+).*" "${1}" }}'
          runbook: 'https://wikitech.wikimedia.org/wiki/Analytics/Systems/Varnishkafka'

      # Yell a little louder when enough errors become a concern.
      - alert: VarnishKafkaDeliveryErrors
        expr: sum by (cluster, instance, site) (irate(varnishkafka_delivery_errors_total[5m])) > 5
        labels:
          team: data-engineering
          severity: critical
        annotations: *varnishkafka-annotations
