##
# flink alerts for the WDQS Streaming Updater
# Not adding k8s-staging yet as there's no way to deploy charts to the staging
# cluster in codfw yet.
# deploy-tag: k8s
groups:
  - name: rdf-streaming-updater
    rules:

## RDF Streaming Updater Flink alerts
      - alert: WdqsStreamingUpdaterFlinkJobNotRunning
        expr: |
          absent(flink_jobmanager_job_uptime{kubernetes_namespace="rdf-streaming-updater", job_name="WDQS_Streaming_Updater"})
        for: 5m
        labels:
          team: search-platform
          severity: critical
        annotations:
          summary: "{{$labels.job_name}} in {{$externalLabels.site}} ({{$externalLabels.prometheus}}) is not running"
          description: "The flink job is not running"
          runbook: https://wikitech.wikimedia.org/wiki/Wikidata_Query_Service/Streaming_Updater
          dashboard: https://grafana.wikimedia.org/d/gCFgfpG7k/flink-session-cluster

      - alert: WcqsStreamingUpdaterFlinkJobNotRunning
        expr: |
          absent(flink_jobmanager_job_uptime{kubernetes_namespace="rdf-streaming-updater", job_name="WCQS_Streaming_Updater"})
        for: 5m
        labels:
          team: search-platform
          severity: critical
        annotations:
          summary: "{{$labels.job_name}} in {{$externalLabels.site}} ({{$externalLabels.prometheus}}) is not running"
          description: "The flink job is not running"
          runbook: https://wikitech.wikimedia.org/wiki/Wikidata_Query_Service/Streaming_Updater
          dashboard: https://grafana.wikimedia.org/d/gCFgfpG7k/flink-session-cluster
      - alert: RdfStreamingUpdaterNotEnoughTaskSlots
        # 24 = 3nodes * 4tm_slots * 2jobs
        expr: |
          flink_jobmanager_taskSlotsTotal{kubernetes_namespace="rdf-streaming-updater"} < 24
        for: 5m
        labels:
          team: search-platform
          severity: warning
        annotations:
          summary: "The flink session cluster {{$labels.kubernetes_namespace}} in {{$externalLabels.site}} ({{$externalLabels.prometheus}}) does not have enough task slots"
          description: "The expected number of task slots is too low for the jobs to function properly"
          runbook: https://wikitech.wikimedia.org/wiki/Wikidata_Query_Service/Streaming_Updater
          dashboard: https://grafana.wikimedia.org/d/gCFgfpG7k/flink-session-cluster

## RDF Streaming Updater Producer alerts
      - alert: RdfStreamingUpdaterFlinkJobUnstable
        # We try to detect crashloop, use the uptime of the job and take its max over a 10minute period.
        # Using resets() or repetive instant checks for 10m do not seem to work because:
        # - the series might differ if the k8s pod crashes making resets unable to detect the resets of the counter
        # - the series might disappear while the job is being restarted making instant checks flappy
        # max_over_time does seem to workaround these problems and will only fail if the series goes away for more than
        # 10 mins in which case the WdqsStreamingUpdaterFlinkJobNotRunning alert should have been triggered a long time ago
        expr: |
          max by (job_name, kubernetes_namespace) (max_over_time(flink_jobmanager_job_uptime{kubernetes_namespace="rdf-streaming-updater"}[10m])) < 300000
        for: 1m
        labels:
          team: search-platform
          severity: critical
        annotations:
          summary: "{{$labels.job_name}} in {{$externalLabels.site}} ({{$externalLabels.prometheus}}) is unstable"
          description: "The flink job has an uptime below 5 minutes for the past 10 minutes, it is probably trying to start in vain"
          runbook: https://wikitech.wikimedia.org/wiki/Wikidata_Query_Service/Streaming_Updater
          dashboard: https://grafana.wikimedia.org/d/gCFgfpG7k/flink-session-cluster

      - alert: RdfStreamingUpdaterFlinkProcessingLatencyIsHigh
        expr: |
          avg by (job_name, kubernetes_namespace) (avg_over_time(flink_taskmanager_job_task_operator_processing_latency_ms{kubernetes_namespace="rdf-streaming-updater"}[5m]) > 600000)
        for: 1m
        labels:
          team: search-platform
          severity: warning
        annotations:
          summary: "Processing latency of {{$labels.job_name}} in {{$externalLabels.site}} ({{$externalLabels.prometheus}}) is above 10 minutes"
          description: "The flink job has a processing latency above 10 minutes"
          runbook: https://wikitech.wikimedia.org/wiki/Wikidata_Query_Service/Streaming_Updater
          dashboard: https://grafana.wikimedia.org/d/fdU5Zx-Mk/wdqs-streaming-updater

## RDF Streaming Updater Consumer alerts
      - alert: RdfStreamingUpdaterHighConsumerUpdateLag
        expr: wdqs_streaming_updater_kafka_stream_consumer_lag_Value / 1000 > 600
        for: 5m
        labels:
          team: search-platform
          severity: warning
        annotations:
          summary: "{{$labels.instance}} has fallen behind applying updates from the RDF Streaming Updater"
          description: "Instance is behind by {{ $value | humanizeDuration }}. Stale data is being served"
          runbook: https://wikitech.wikimedia.org/wiki/Wikidata_Query_Service/Streaming_Updater
          dashboard: https://grafana.wikimedia.org/d/fdU5Zx-Mk/wdqs-streaming-updater

## Swift usage alerts, alert if > 1TB is used
      - alert: RdfStreamingUpdaterSpaceUsageTooHigh
        expr: swift_account_stats_bytes_total{account="AUTH_wdqs"} > 1099511627776
        for: 1m
        labels:
          team: search-platform
          severity: warning
        annotations:
          summary: "The RDF Streaming Updater is using more than 1TiB of storage"
          description: "The containers owned by {{$labels.account}} are using {{ $value | humanize1024 }}, this is more than expected."
          runbook: https://wikitech.wikimedia.org/wiki/Wikidata_Query_Service/Streaming_Updater
          dashboard: https://grafana.wikimedia.org/d/fdU5Zx-Mk/wdqs-streaming-updater
